# Given a FASTQ file generated by a long-read sequencer such as PacBio,
# this script aligns the reads to a reference genome, identifies structural variants (SVs),
# and summarizes the detected SVs with relevant information.
#
# Dependencies:
# 1) Input data:
#    - Reference genome in FASTA format
#    - Optional prebuilt Minimap2 index (.mmi) corresponding to the reference
#    - A FASTQ file generated by a long-read sequencer (e.g., PacBio)
#
# 2) External tools (tested versions):
#    - seqkit    v2.10.1
#    - minimap2  v2.30-r1287
#    - samtools  v1.22.1
#    - sniffles2 v2.6.3
#
# 3) Python dependency (tested version):
#    - pysam     v0.23.3
#
# TO RUN: python ./longread_sv_pipeline.py -f <FASTQ input file> -r <reference FASTA> [-i <reference index>]
# For example: python ./longread_sv_pipeline.py -f ./TestData/brca1_with_sva_hifi.fastq -r ./TestData/chr17.fasta -i ./TestData/chr17.mmi

import argparse
import subprocess
import shlex
import pysam
from collections import Counter
from datetime import datetime
from pathlib import Path

SCRIPT_DIR = Path(__file__).resolve().parent

# Given a dictionary of FASTQ statistics,
# check basic properties to confirm that the file appears to be a valid
# long-read dataset.
def is_fastq_valid_longread(stats):
    num_reads = int(stats.get("num_seqs", 0).replace(",", ""))
    avg_len = float(stats.get("avg_len", 0).replace(",", ""))
    min_len = float(stats.get("min_len", 0).replace(",", ""))

    issues = []
    if num_reads == 0:
        issues.append("no reads found in FASTQ file")
    if avg_len < 1000:
        issues.append(f"average read length ({avg_len:.0f} bp) is unusually short for HiFi data")
    if min_len < 100:
        issues.append(f"some reads are extremely short (min length {min_len:.0f} bp)")
    
    if issues:
        return (False, "\n".join(issues))
    return (True, "")

# Print a summary of a FASTQ fileâ€™s statistics and return a dictionary of those values.
def summarize_fastq(fastq_path):
    result = run_command(
        ["seqkit", "stats", fastq_path],
        description="FASTQ Summary (seqkit stats)",
        capture_output=True
    )

    lines = result.stdout.strip().splitlines()

    header = lines[0].split()
    values = lines[1].split()

    stats = dict(zip(header, values))

    print(result.stdout.strip())
    
    return stats

# Align reads to the reference genome, then convert, sort, and index the results
def make_bam(reference_index, fastq_file, output_dir):
    reference_index = Path(reference_index).expanduser()
    fastq_file = Path(fastq_file).expanduser()
    output_dir = Path(output_dir).expanduser()
    output_dir.mkdir(parents=True, exist_ok=True)

    sam_path = output_dir / (fastq_file.stem + ".sam")
    bam_path = output_dir / (fastq_file.stem + ".sorted.bam")

    # Align reads to given reference
    run_command(
        ["minimap2", "-t", "8", "-ax", "map-hifi", str(reference_index), str(fastq_file), "-o", str(sam_path)],
        "Aligning reads with minimap2", capture_output=False, warn_about_long_process=True
    )
    # Convert sam to bam and sort
    cmd = (
        f"samtools view -bS {sam_path} | "
        f"samtools sort -o {bam_path}"
    )
    run_command(
        cmd,
        "Converting SAM to sorted BAM", capture_output=False, warn_about_long_process=True
    )
    cmd = [
        "samtools",
        "index",
        str(bam_path)
    ]
    run_command(cmd, f"Indexing BAM file: {bam_path.name}", capture_output=False, warn_about_long_process=True)

    return bam_path

# Run minimap2 to build an index from the provided reference genome
def build_minimap2_index(reference_fasta, output_index):
    result = run_command(
        ["minimap2", "-d", str(output_index), str(reference_fasta)],
        description="Building Minimap2 index",
        capture_output=False
    )

def make_vcf(fastq, bam, outputs_dir, ref):
    vcf = Path(outputs_dir) / (Path(fastq).stem + ".sv.vcf")

    cmd = [
        "sniffles",
        "--input", str(bam),
        "--vcf", str(vcf),
        "--reference", str(ref),
        "--threads", "8",
    ]

    result = run_command(cmd, "Running Sniffles for structural variant detection", capture_output=False)
    print((result.stdout or "") + (result.stderr or ""))

    return vcf

def summarize_svs(vcf_path):
    vcf = pysam.VariantFile(vcf_path)
    sv_counts = Counter()
    print(f"\n*********** Structural Variant Summary ***********")
    print(f"{'CHROM':<8} {'POS':<10} {'TYPE':<6} {'LEN':<8}")
    print("-" * 40)

    for rec in vcf.fetch():
        svtype = rec.info.get("SVTYPE", "?")
        svlen = rec.info.get("SVLEN", [0])[0] if isinstance(rec.info.get("SVLEN"), list) else rec.info.get("SVLEN", 0)
        sv_counts[svtype] += 1
        print(f"{rec.chrom:<8} {rec.pos:<10} {svtype:<6} {svlen:<8}")

    print("\n*********** Counts by Type ***********")
    for svtype, count in sv_counts.items():
        print(f"{svtype}: {count}")

def run_command(cmd, description, capture_output=False, warn_about_long_process=False):
    print(f"\n\n*********** {description} ***********")
    if isinstance(cmd, list):
        print(f"Command: {shlex.join(map(str, cmd))}")
    else:
        print(f"Command: {cmd}")
    if warn_about_long_process:
        print(f"Please be patient. This process can take a few minutes.")

    try:
        result = subprocess.run(
            cmd,
            shell=isinstance(cmd, str),
            check=True,
            text=True,
            capture_output=capture_output
        )
        return result
    except subprocess.CalledProcessError as e:
        print(f"Error: {e}")
        if e.stderr:
            print(e.stderr)
        exit(1)
    except FileNotFoundError:
        print(f"Command not found: {cmd[0]}. Make sure it's installed and in your PATH.")
        exit(1)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description=(
            "A pipeline for detecting structural variants in long-read sequencing data."
        )
    )
    parser.add_argument(
        "-r", "--reference",
        type=Path,
        required=True,
        help="Path to the reference genome in FASTA format."
    )
    parser.add_argument(
        "-f", "--fastq",
        type=Path,
        required=True,
        help="Path to the sample data FASTQ file generated by a long-read sequencer."
    )
    parser.add_argument(
        "-i", "--index",
        type=Path,
        required=False,
        help="Optional path to a prebuilt minimap2 index (.mmi). "
             "If not provided, the index will be generated automatically."
    )
    args = parser.parse_args()

    # Verify that the FASTQ file appears to contain valid long-read data
    fastq_stats = summarize_fastq(args.fastq)
    is_valid = is_fastq_valid_longread(fastq_stats)
    if not is_valid[0]:
        response = input(f"Your input FASTQ file has some issues:\n{is_valid[1]}. \n\nDo you want to continue? (y/n)")
        if response != "y":
            exit()

    # Index the given reference genome, if the index has not been provided (save in the same directory as the reference genome)
    ref_index = args.index
    if not args.index:
        ref_index = args.reference.with_suffix(".mmi")
        build_minimap2_index(args.reference, ref_index)

    # Align the FASTQ, build a sorted BAM, find and print structural variants
    outputs_dir = SCRIPT_DIR / "Outputs" / datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    bam = make_bam(ref_index, args.fastq, outputs_dir)
    vcf = make_vcf(args.fastq, bam, outputs_dir, args.reference)
    summarize_svs(vcf)
            
        
